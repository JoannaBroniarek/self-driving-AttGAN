{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#\n",
    "# define earth mover distance (wasserstein loss)\n",
    "#\n",
    "\n",
    "LEARNING_RATE = 0.0002\n",
    "BETA_1 = 0.5\n",
    "BETA_2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rand_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bdce7e6c2408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# sample a batch of noise (generator input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# sample a batch of real images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rand_dim' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "def em_loss(y_coefficients, y_pred):\n",
    "    return tf.reduce_mean(tf.multiply(y_coefficients, y_pred))\n",
    "\n",
    "#\n",
    "# construct computation graph for calculating the gradient penalty (improved wGAN) and training the discriminator\n",
    "#\n",
    "\n",
    "# sample a batch of noise (generator input)\n",
    "_z = tf.placeholder(tf.float32, shape=(batch_size, rand_dim))\n",
    "\n",
    "# sample a batch of real images\n",
    "_x = tf.placeholder(tf.float32, shape=(batch_size, img_height, img_width, img_channels))\n",
    "\n",
    "# generate a batch of images with the current generator\n",
    "_g_z = generator_model(_z)\n",
    "\n",
    "# calculate `x_hat`\n",
    "epsilon = tf.placeholder(tf.float32, shape=(batch_size, 1, 1, 1))\n",
    "x_hat = epsilon * _x + (1.0 - epsilon) * _g_z\n",
    "\n",
    "# gradient penalty\n",
    "gradients = tf.gradients(discriminator_model(x_hat), [x_hat])\n",
    "_gradient_penalty = 10.0 * tf.square(tf.norm(gradients[0], ord=2) - 1.0)\n",
    "\n",
    "# calculate discriminator's loss\n",
    "_disc_loss = em_loss(tf.ones(batch_size), discriminator_model(_g_z)) - \\\n",
    "    em_loss(tf.ones(batch_size), discriminator_model(_x)) + \\\n",
    "    _gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_uniform_1:0' shape=(32, 1, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_penalty(f, real, fake=None):\n",
    "    def _interpolate(a, b):\n",
    "        with tf.name_scope('interpolate'):\n",
    "            shape = [tf.shape(a)[0]] + [1] * (a.shape.ndims - 1)\n",
    "            alpha = tf.random_uniform(shape=shape, minval=0., maxval=1.)\n",
    "            inter = a + alpha * (b - a)\n",
    "            inter.set_shape(a.get_shape().as_list())\n",
    "            return inter\n",
    "\n",
    "    with tf.name_scope('gradient_penalty'):\n",
    "        x = _interpolate(real, fake)\n",
    "        pred = f(x) #discriminator\n",
    "        if isinstance(pred, tuple):\n",
    "            pred = pred[0]\n",
    "        grad = tf.gradients(pred, x)[0]\n",
    "        norm = tf.norm(slim.flatten(grad), axis=1)\n",
    "        gp = tf.reduce_mean((norm - 1.)**2)\n",
    "        return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if self.gan_type == 'wgan-gp':\n",
    "            epsilon = tf.random_uniform(\n",
    "                shape=[self.batch_size, 1, 1, 1], minval=0., maxval=1.)\n",
    "            interpolated_image = self.image + epsilon * (fake_image - self.image)\n",
    "            d_interpolated = D(interpolated_image)\n",
    "        # }}}\n",
    "\n",
    "        # Build losses {{{\n",
    "        # =========\n",
    "        # compute loss and prob\n",
    "        if self.gan_type == 'lsgan':\n",
    "            d_real_loss = tf.reduce_mean((d_real - tf.ones_like(d_real))**2)\n",
    "            d_fake_loss = tf.reduce_mean((d_fake - tf.zeros_like(d_fake))**2)\n",
    "            g_loss = tf.reduce_mean((d_fake - tf.ones_like(d_fake))**2)\n",
    "        elif self.gan_type == 'hinge':\n",
    "            d_real_loss = tf.reduce_mean(tf.nn.relu(tf.ones_like(d_real) - d_real))\n",
    "            d_fake_loss = tf.reduce_mean(tf.nn.relu(tf.ones_like(d_fake) + d_fake))\n",
    "            g_loss = -tf.reduce_mean(d_fake)\n",
    "        elif self.gan_type == 'wgan-gp':\n",
    "            d_loss = tf.reduce_mean(d_fake) - tf.reduce_mean(d_real)\n",
    "            g_loss = -tf.reduce_mean(d_fake)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        d_real_prob = tf.reduce_mean(d_real)\n",
    "        d_fake_prob = tf.reduce_mean(d_fake)\n",
    "\n",
    "        # compute gradient penalty\n",
    "        if self.gan_type == 'wgan-gp':\n",
    "            grad_d_interpolated = tf.gradients(\n",
    "                d_interpolated, [interpolated_image])[0]\n",
    "            slopes = tf.sqrt(1e-8 + tf.reduce_sum(\n",
    "                tf.square(grad_d_interpolated), axis=[1, 2, 3]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n",
    "\n",
    "        if self.gan_type in ['lsgan', 'hinge']:\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "        self.d_loss = d_loss\n",
    "        self.g_loss = g_loss\n",
    "        if self.gan_type == 'wgan-gp':\n",
    "            self.d_loss += self.gamma * gradient_penalty\n",
    "            tf.summary.scalar(\"loss/gradient_penalty\", gradient_penalty)\n",
    "        # }}}\n",
    "\n",
    "        # TensorBoard summaries {{{\n",
    "        # =========\n",
    "        if self.gan_type == 'lsgan':\n",
    "            tf.summary.scalar(\"loss/d_real_loss\", d_real_loss)\n",
    "            tf.summary.scalar(\"loss/d_fake_loss\", d_fake_loss)\n",
    "        tf.summary.scalar(\"loss/d_real_prob\", d_real_prob)\n",
    "        tf.summary.scalar(\"loss/d_fake_prob\", d_fake_prob)\n",
    "        tf.summary.scalar(\"loss/d_loss\", self.d_loss)\n",
    "        tf.summary.scalar(\"loss/g_loss\", self.g_loss)\n",
    "\n",
    "        def d_output_vis(d_output):\n",
    "            d_vis = tf.tile(tf.image.resize_nearest_neighbor(\n",
    "                tf.clip_by_value(d_output, -1, 1),\n",
    "                [self.h, self.w]), [1, 1, 1, self.c_dim])\n",
    "            return d_vis\n",
    "\n",
    "        tb_d = tf.concat([d_output_vis(d_real), d_output_vis(d_fake)], axis=2)\n",
    "        if self.gan_type == 'wgan-gp':\n",
    "            # normlize to [-1, 1]\n",
    "            tb_d -= tf.reduce_min(tb_d)\n",
    "            tb_d /= tf.reduce_max(tb_d)\n",
    "            tb_d = tb_d * 2 - 1\n",
    "        tb_img = tf.concat([self.image, fake_image], axis=2)\n",
    "        tb_image = tf.concat([tb_img, tb_d], axis=1)\n",
    "        tf.summary.image(\"img\", tb_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
