{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import numpy as np\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# these should go into ops.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ostyk/Desktop/self-driving-AttGAN/code\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"conv2d\", padding = 'VALID'):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        \n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding=padding)\n",
    "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        return tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "\n",
    "    \n",
    "def deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, name=\"deconv2d\", stddev=0.02, with_w=False):\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "\n",
    "        deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        return tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "\n",
    "\n",
    "    \n",
    "def encoder(inputs, name = 'G_encoder', reuse=tf.AUTO_REUSE, is_training = True):\n",
    "    \"\"\"\n",
    "    encoder function\n",
    "    :param: inputs\n",
    "    :param: name\n",
    "    :return list of layers:\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    num_blocks = 5\n",
    "    filters = 64\n",
    "    kernel_size = 4\n",
    "    strides = 2\n",
    "    layers = [inputs]\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            \n",
    "            conv = conv2d(inputs, filters, kernel_size, kernel_size, strides, strides, name = str(i+1))\n",
    "            batch_norm = tf.contrib.layers.batch_norm(conv, scale=True)\n",
    "            inputs = leaky_relu = tf.nn.leaky_relu(batch_norm, alpha = leakyrelu_alpha)\n",
    "            \n",
    "            filters += filters\n",
    "            layers.append(inputs)\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "def decoder(inputs, attribute, name = 'G_decoder', reuse=None, is_training = True):\n",
    "    \"\"\"\n",
    "    decoder function\n",
    "    :param: inputs (list of layers from encoder)\n",
    "    :param: name\n",
    "    :attribute: attribute (label)\n",
    "    :return tanh(conv5):\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    filters = 1024\n",
    "    kernel_size = 4\n",
    "    strides = 2\n",
    "    input_ = inputs[-1]\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "                \n",
    "        for ind in list(reversed(range(len(inputs)))):\n",
    "            \n",
    "            outout_shape = inputs[ind-1].get_shape().as_list()\n",
    "            \n",
    "            if ind==1:\n",
    "                deconv = deconv2d(input_, outout_shape, kernel_size, kernel_size, strides, strides, name = \"deconv_{}\".format(ind))\n",
    "                return tf.nn.tanh(deconv)\n",
    "            \n",
    "            deconv = deconv2d(input_, outout_shape, kernel_size, kernel_size, strides, strides, name = str(ind-1))\n",
    "            concatenated = tf.concat([deconv, inputs[ind-1]], axis=3)\n",
    "\n",
    "            batch_norm = tf.contrib.layers.batch_norm(concatenated, scale=True)\n",
    "            \n",
    "            input_ = leaky_relu = tf.nn.leaky_relu(batch_norm, alpha = leakyrelu_alpha, name = \"ReLU_{}\".format(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_scene:0' shape=(32, 128, 128, 3) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu:0' shape=(32, 63, 63, 64) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_1:0' shape=(32, 30, 30, 128) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_2:0' shape=(32, 14, 14, 256) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_3:0' shape=(32, 6, 6, 512) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_4:0' shape=(32, 2, 2, 1024) dtype=float32>]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "tf.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "input_enc = tf.placeholder(tf.float32,shape=[BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,3],name=\"input_scene\")\n",
    "input_dec = tf.placeholder(tf.float32,shape=[BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,3],name=\"z\")\n",
    "label = tf.placeholder(tf.float32,shape=[BATCH_SIZE, NUM_CLASSES],name=\"input_label\")\n",
    "\n",
    "gen_enc = encoder(input_enc, reuse=tf.AUTO_REUSE)\n",
    "gen_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator decoder input and instance\n",
    "Z_SHAPE = gen_enc[-1].shape\n",
    "N_layers = len(gen_enc)\n",
    "input_dec = tf.placeholder(tf.float32,shape=[N_layers, BATCH_SIZE,Z_SHAPE[1].value,Z_SHAPE[2].value,Z_SHAPE[3].value],name=\"z\")\n",
    "label = tf.placeholder(tf.float32,shape=[BATCH_SIZE, NUM_CLASSES],name=\"input_label\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dec = decoder(gen_enc, label, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 128, 128, 3]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dec.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_var, name, reuse=None):\n",
    "    with tf.variable_scope(name,reuse=reuse):\n",
    "        leakyrelu_alpha = 0.2\n",
    "        num_blocks = 5\n",
    "        filters = 64\n",
    "        kernel_size = 4\n",
    "        strides = 2\n",
    "        # Five intermediate blocks : conv + layer norm + instance norm + leaky relu\n",
    "        for i in range(num_blocks):\n",
    "            conv = tf.layers.conv2d(inputs = input_var,\n",
    "                                    filters = filters, \n",
    "                                    kernel_size = kernel_size,\n",
    "                                    padding = 'valid', \n",
    "                                    strides = strides,\n",
    "                                    name = \"{}_{}_{}\".format(name, conv.__name__, i+1))\n",
    "            layer_norm = tf.contrib.layers.layer_norm(conv, name = \"{}_{}_{}\".format(name, layer_norm.__name__, i+1))\n",
    "            instance_norm = tf.contrib.layers.instance_norm(layer_norm, name = \"{}_{}_{}\".format(name, instance_norm.__name__, i+1))\n",
    "            leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "            input_var = leaky_relu_out\n",
    "            filters += filters\n",
    "\n",
    "        # Output block : fc(1024) + layer norm + instance norm + leaky relu\n",
    "        output_blocks = input_var\n",
    "        fc = tf.contrib.layers.fully_connected(output_blocks, \n",
    "                                               num_outputs = 1024,\n",
    "                                               name = \"{}_{}_{}\".format(name, fc.__name__, \"out\"))\n",
    "        layer_norm = tf.contrib.layers.layer_norm(fc,\n",
    "                                                  name = \"{}_{}_{}\".format(layer_norm, layer_.__name__, \"out\"))\n",
    "        instance_norm = tf.contrib.layers.instance_norm(layer_norm, \n",
    "                                                        name = \"{}_{}_{}\".format(name, instance_norm.__name__, i+1))\n",
    "        leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "        # Output\n",
    "        return tf.contrib.layers.fully_connected(leaky_relu_out, num_outputs = 1)\n",
    "\n",
    "def classifier(input_var, name, reuse=None):\n",
    "    with tf.variable_scope(name,reuse=reuse):\n",
    "        leakyrelu_alpha = 0.2\n",
    "        num_blocks = 5\n",
    "        filters = 64\n",
    "        kernel_size = 4\n",
    "        strides = 2\n",
    "        \n",
    "        # Five intermediate blocks : conv + layer norm + instance norm + leaky relu\n",
    "        for i in range(num_blocks):\n",
    "            conv = tf.layers.conv2d(inputs = input_var, \n",
    "                                    filters = filters,\n",
    "                                    kernel_size = kernel_size, \n",
    "                                    padding = 'valid', \n",
    "                                    strides = strides,\n",
    "                                    name = \"{}_{}_{}\".format(name, conv.__name__, i+1))\n",
    "            layer_norm = tf.contrib.layers.layer_norm(conv)\n",
    "            instance_norm = tf.contrib.layers.instance_norm(layer_norm)\n",
    "            leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "            input_var = leaky_relu_out\n",
    "            filters += filters\n",
    "\n",
    "        # Output block : fc(1024) + layer norm + instance norm + leaky relu\n",
    "        output_blocks = input_var\n",
    "        fc = tf.contrib.layers.fully_connected(output_blocks, num_outputs=1024)\n",
    "        layer_norm = tf.contrib.layers.layer_norm(fc)\n",
    "        instance_norm = tf.contrib.layers.instance_norm(layer_norm)\n",
    "        leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "        # Output\n",
    "        out = tf.contrib.layers.fully_connected(leaky_relu_out, num_outputs=2)\n",
    "        \n",
    "        return tf.nn.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'tfds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-54d8720573e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'tfds'"
     ]
    }
   ],
   "source": [
    "tf.tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.19863377, 0.75380188, 9.21448324, 3.2167068 , 7.32243162,\n",
       "       3.21890819, 3.23853706, 7.51599995, 0.93957077, 5.17013964,\n",
       "       7.76885567, 0.62369543, 7.86392748, 1.48798541, 0.21778457,\n",
       "       6.15481792, 4.77598977, 5.83625036, 6.3224709 , 9.60251797,\n",
       "       2.99249239, 2.62329686, 0.71307585, 3.99371344, 2.83914563,\n",
       "       3.25565988, 7.3897957 , 7.09405094, 9.19581555, 2.26938345,\n",
       "       1.52701994, 0.81092916, 1.6415883 , 8.12211851, 9.70005502,\n",
       "       7.09492335, 3.52856333, 1.08269312, 2.81801129, 2.03607664,\n",
       "       5.98082455, 3.41794094, 7.35546113, 4.341086  , 6.55884717,\n",
       "       0.95678011, 7.82094103, 5.87694765, 4.28320108, 7.59860797,\n",
       "       1.34016418, 8.19114921, 5.11393919, 4.27831104, 7.00838451,\n",
       "       5.40895453, 1.24412798, 4.91450353, 6.67549771, 5.48912537,\n",
       "       5.86176311, 3.92520827, 9.9062464 , 4.89820769, 9.95527057,\n",
       "       4.41615187, 9.11305641, 3.51402106, 5.69346415, 3.52905663,\n",
       "       8.12813785, 3.765514  , 9.4730145 , 6.2002977 , 4.92801853,\n",
       "       0.92094796, 3.74673943, 3.82122843, 6.58050042, 2.59951143,\n",
       "       2.59733421, 5.70363422, 8.85140937, 4.16355794, 4.82258075,\n",
       "       9.22815183, 0.50782178, 3.19715149, 0.99589178, 9.72675424])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random(90)*10\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 9, 3, 7, 3, 3, 7, 0, 5, 7, 0, 7, 1, 0, 6, 4, 5, 6, 9, 2, 2,\n",
       "       0, 3, 2, 3, 7, 7, 9, 2, 1, 0, 1, 8, 9, 7, 3, 1, 2, 2, 5, 3, 7, 4,\n",
       "       6, 0, 7, 5, 4, 7, 1, 8, 5, 4, 7, 5, 1, 4, 6, 5, 5, 3, 9, 4, 9, 4,\n",
       "       9, 3, 5, 3, 8, 3, 9, 6, 4, 0, 3, 3, 6, 2, 2, 5, 8, 4, 4, 9, 0, 3,\n",
       "       0, 9], dtype=uint8)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
