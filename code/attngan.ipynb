{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import numpy as np\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# these should go into ops.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ostyk/Desktop/self-driving-AttGAN/code\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"conv2d\", padding = 'VALID'):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        \n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding=padding)\n",
    "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        return tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "\n",
    "    \n",
    "def deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, name=\"deconv2d\", stddev=0.02, with_w=False):\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "\n",
    "        deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        return tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "\n",
    "\n",
    "    \n",
    "def encoder(inputs, name = 'G_encoder', reuse=tf.AUTO_REUSE, is_training = True):\n",
    "    \"\"\"\n",
    "    encoder function\n",
    "    :param: inputs\n",
    "    :param: name\n",
    "    :return list of layers:\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    num_blocks = 5\n",
    "    filters = 64\n",
    "    kernel_size = 4\n",
    "    strides = 2\n",
    "    layers = [inputs]\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            \n",
    "            conv = conv2d(inputs, filters, kernel_size, kernel_size, strides, strides, name = str(i+1))\n",
    "            batch_norm = tf.contrib.layers.batch_norm(conv)\n",
    "            inputs = leaky_relu = tf.nn.leaky_relu(batch_norm, alpha = leakyrelu_alpha)\n",
    "            \n",
    "            filters += filters\n",
    "            layers.append(inputs)\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "def decoder(inputs, label, name = 'G_decoder', reuse=None, is_training = True):\n",
    "    \"\"\"\n",
    "    decoder function\n",
    "    :param: inputs (list of layers from encoder)\n",
    "    :param: name\n",
    "    :return tanh(conv5):\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    filters = 1024\n",
    "    kernel_size = 4\n",
    "    strides = 2\n",
    "    input_ = inputs[-1]\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "                \n",
    "        for ind in list(reversed(range(len(inputs)))):\n",
    "            outout_shape = [i.value for i in list(inputs[ind-1].shape)]\n",
    "            \n",
    "            if ind==1:\n",
    "                deconv = deconv2d(input_, outout_shape, kernel_size, kernel_size, strides, strides, name = \"deconv_{}\".format(ind))\n",
    "                return tf.nn.tanh(deconv)\n",
    "            \n",
    "            deconv = deconv2d(input_, outout_shape, kernel_size, kernel_size, strides, strides, name = str(ind-1))\n",
    "            concatenated = tf.concat([deconv, inputs[ind-1]], axis=3)\n",
    "\n",
    "            batch_norm = tf.contrib.layers.batch_norm(concatenated)\n",
    "            \n",
    "            input_ = leaky_relu = tf.nn.leaky_relu(batch_norm, alpha = leakyrelu_alpha, name = \"ReLU_{}\".format(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_scene:0' shape=(32, 128, 128, 3) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu:0' shape=(32, 63, 63, 64) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_1:0' shape=(32, 30, 30, 128) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_2:0' shape=(32, 14, 14, 256) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_3:0' shape=(32, 6, 6, 512) dtype=float32>,\n",
       " <tf.Tensor 'G_encoder/LeakyRelu_4:0' shape=(32, 2, 2, 1024) dtype=float32>]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "tf.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "input_enc = tf.placeholder(tf.float32,shape=[BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,3],name=\"input_scene\")\n",
    "input_dec = tf.placeholder(tf.float32,shape=[BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,3],name=\"z\")\n",
    "label = tf.placeholder(tf.float32,shape=[BATCH_SIZE, NUM_CLASSES],name=\"input_label\")\n",
    "\n",
    "gen_enc = encoder(input_enc, reuse=tf.AUTO_REUSE)\n",
    "gen_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator decoder input and instance\n",
    "Z_SHAPE = gen_enc[-1].shape\n",
    "N_layers = len(gen_enc)\n",
    "input_dec = tf.placeholder(tf.float32,shape=[N_layers, BATCH_SIZE,Z_SHAPE[1].value,Z_SHAPE[2].value,Z_SHAPE[3].value],name=\"z\")\n",
    "label = tf.placeholder(tf.float32,shape=[BATCH_SIZE, NUM_CLASSES],name=\"input_label\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dec = decoder(gen_enc, label, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'G_decoder/Tanh:0' shape=(32, 128, 128, 3) dtype=float32>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_var, name, reuse=None):\n",
    "    with tf.variable_scope(name,reuse=reuse):\n",
    "        leakyrelu_alpha = 0.2\n",
    "        num_blocks = 5\n",
    "        filters = 64\n",
    "        kernel_size = 4\n",
    "        strides = 2\n",
    "        # Five intermediate blocks : conv + layer norm + instance norm + leaky relu\n",
    "        for i in range(num_blocks):\n",
    "            conv = tf.layers.conv2d(inputs = input_var,\n",
    "                                    filters = filters, \n",
    "                                    kernel_size = kernel_size,\n",
    "                                    padding = 'valid', \n",
    "                                    strides = strides,\n",
    "                                    name = \"{}_{}_{}\".format(name, conv.__name__, i+1))\n",
    "            layer_norm = tf.contrib.layers.layer_norm(conv, name = \"{}_{}_{}\".format(name, layer_norm.__name__, i+1))\n",
    "            instance_norm = tf.contrib.layers.instance_norm(layer_norm, name = \"{}_{}_{}\".format(name, instance_norm.__name__, i+1))\n",
    "            leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "            input_var = leaky_relu_out\n",
    "            filters += filters\n",
    "\n",
    "        # Output block : fc(1024) + layer norm + instance norm + leaky relu\n",
    "        output_blocks = input_var\n",
    "        fc = tf.contrib.layers.fully_connected(output_blocks, \n",
    "                                               num_outputs = 1024,\n",
    "                                               name = \"{}_{}_{}\".format(name, fc.__name__, \"out\"))\n",
    "        layer_norm = tf.contrib.layers.layer_norm(fc,\n",
    "                                                  name = \"{}_{}_{}\".format(layer_norm, layer_.__name__, \"out\"))\n",
    "        instance_norm = tf.contrib.layers.instance_norm(layer_norm, \n",
    "                                                        name = \"{}_{}_{}\".format(name, instance_norm.__name__, i+1))\n",
    "        leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "        # Output\n",
    "        return tf.contrib.layers.fully_connected(leaky_relu_out, num_outputs = 1)\n",
    "\n",
    "def classifier(input_var, name, reuse=None):\n",
    "    with tf.variable_scope(name,reuse=reuse):\n",
    "        leakyrelu_alpha = 0.2\n",
    "        num_blocks = 5\n",
    "        filters = 64\n",
    "        kernel_size = 4\n",
    "        strides = 2\n",
    "        \n",
    "        # Five intermediate blocks : conv + layer norm + instance norm + leaky relu\n",
    "        for i in range(num_blocks):\n",
    "            conv = tf.layers.conv2d(inputs = input_var, \n",
    "                                    filters = filters,\n",
    "                                    kernel_size = kernel_size, \n",
    "                                    padding = 'valid', \n",
    "                                    strides = strides,\n",
    "                                    name = \"{}_{}_{}\".format(name, conv.__name__, i+1))\n",
    "            layer_norm = tf.contrib.layers.layer_norm(conv)\n",
    "            instance_norm = tf.contrib.layers.instance_norm(layer_norm)\n",
    "            leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "            input_var = leaky_relu_out\n",
    "            filters += filters\n",
    "\n",
    "        # Output block : fc(1024) + layer norm + instance norm + leaky relu\n",
    "        output_blocks = input_var\n",
    "        fc = tf.contrib.layers.fully_connected(output_blocks, num_outputs=1024)\n",
    "        layer_norm = tf.contrib.layers.layer_norm(fc)\n",
    "        instance_norm = tf.contrib.layers.instance_norm(layer_norm)\n",
    "        leaky_relu_out = tf.nn.leaky_relu(instance_norm, alpha = leakyrelu_alpha)\n",
    "\n",
    "        # Output\n",
    "        out = tf.contrib.layers.fully_connected(leaky_relu_out, num_outputs=2)\n",
    "        \n",
    "        return tf.nn.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
